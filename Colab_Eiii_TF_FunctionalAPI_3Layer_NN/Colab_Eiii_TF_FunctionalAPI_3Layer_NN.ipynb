{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8cb2cb4",
   "metadata": {},
   "source": [
    "# Colab E-iii: TensorFlow Functional API - 3-Layer Deep Neural Network\n",
    "\n",
    "## Overview\n",
    "- **TensorFlow Functional API** (`tf.keras.Model` with explicit Input/Output)\n",
    "- Allows complex model topologies (multi-input, multi-output, skip connections)\n",
    "- Uses `model.compile()` and `model.fit()` for training\n",
    "- Same 3-variable non-linear regression problem\n",
    "\n",
    "### Target Non-Linear Equation\n",
    "$$y = \\sin(x_1) \\cdot x_2^2 + \\cos(x_3) \\cdot x_1 + x_2 \\cdot x_3^2$$\n",
    "\n",
    "### Network Architecture (Functional API)\n",
    "```\n",
    "Input(3) --> Dense(64, ReLU) --> Dense(32, ReLU) --> Dense(16, ReLU) --> Dense(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8601fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 1: Imports\n",
    "# ============================================================\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 2: Generate Synthetic Data\n",
    "# ============================================================\n",
    "N_SAMPLES = 1000\n",
    "\n",
    "x1 = np.random.uniform(-2, 2, (N_SAMPLES, 1)).astype(np.float32)\n",
    "x2 = np.random.uniform(-2, 2, (N_SAMPLES, 1)).astype(np.float32)\n",
    "x3 = np.random.uniform(-2, 2, (N_SAMPLES, 1)).astype(np.float32)\n",
    "\n",
    "y = (np.sin(x1) * x2**2 + np.cos(x3) * x1 + x2 * x3**2).astype(np.float32)\n",
    "X = np.hstack([x1, x2, x3])\n",
    "\n",
    "X_mean, X_std = X.mean(axis=0), X.std(axis=0)\n",
    "y_mean, y_std = y.mean(), y.std()\n",
    "X_norm = ((X - X_mean) / X_std).astype(np.float32)\n",
    "y_norm = ((y - y_mean) / y_std).astype(np.float32)\n",
    "\n",
    "split = int(0.8 * N_SAMPLES)\n",
    "X_train, X_test = X_norm[:split], X_norm[split:]\n",
    "y_train, y_test = y_norm[:split], y_norm[split:]\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"y = sin(x1)*x2² + cos(x3)*x1 + x2*x3²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fed03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 3: 4D Data Visualization\n",
    "# ============================================================\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "sc1 = ax1.scatter(X[:, 0], X[:, 1], X[:, 2], c=y.flatten(), cmap='viridis', s=5, alpha=0.6)\n",
    "ax1.set_xlabel('x1'); ax1.set_ylabel('x2'); ax1.set_zlabel('x3')\n",
    "ax1.set_title('4D: x1,x2,x3 (color=y)')\n",
    "plt.colorbar(sc1, ax=ax1, shrink=0.5)\n",
    "\n",
    "pca2 = PCA(n_components=2); Xp2 = pca2.fit_transform(X)\n",
    "ax2 = fig.add_subplot(132)\n",
    "sc2 = ax2.scatter(Xp2[:, 0], Xp2[:, 1], c=y.flatten(), cmap='viridis', s=5, alpha=0.6)\n",
    "ax2.set_xlabel('PC1'); ax2.set_ylabel('PC2'); ax2.set_title('PCA 2D')\n",
    "plt.colorbar(sc2, ax=ax2, shrink=0.5)\n",
    "\n",
    "pca3 = PCA(n_components=3); Xp3 = pca3.fit_transform(X)\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "sc3 = ax3.scatter(Xp3[:, 0], Xp3[:, 1], Xp3[:, 2], c=y.flatten(), cmap='viridis', s=5, alpha=0.6)\n",
    "ax3.set_xlabel('PC1'); ax3.set_ylabel('PC2'); ax3.set_zlabel('PC3')\n",
    "ax3.set_title('PCA 3D (4D)')\n",
    "plt.colorbar(sc3, ax=ax3, shrink=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a2cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 4: Build Model Using Functional API\n",
    "# ============================================================\n",
    "# The Functional API defines the model as a DAG (Directed Acyclic Graph)\n",
    "# Each layer is called on the output of the previous layer\n",
    "\n",
    "def build_functional_model():\n",
    "    \"\"\"\n",
    "    Build 3-Layer DNN using TensorFlow Functional API.\n",
    "    \n",
    "    Key difference from Sequential:\n",
    "    - Explicit Input tensor\n",
    "    - Model defined as a graph of layer calls\n",
    "    - Supports complex topologies (multi-input/output, skip connections)\n",
    "    \"\"\"\n",
    "    # Define input\n",
    "    inputs = Input(shape=(3,), name='input_features')\n",
    "    \n",
    "    # Hidden Layer 1: 64 neurons, ReLU\n",
    "    x = layers.Dense(64, activation='relu',\n",
    "                     kernel_initializer='he_normal',\n",
    "                     name='hidden_1')(inputs)\n",
    "    \n",
    "    # Hidden Layer 2: 32 neurons, ReLU\n",
    "    x = layers.Dense(32, activation='relu',\n",
    "                     kernel_initializer='he_normal',\n",
    "                     name='hidden_2')(x)\n",
    "    \n",
    "    # Hidden Layer 3: 16 neurons, ReLU\n",
    "    x = layers.Dense(16, activation='relu',\n",
    "                     kernel_initializer='he_normal',\n",
    "                     name='hidden_3')(x)\n",
    "    \n",
    "    # Output Layer: 1 neuron, Linear\n",
    "    outputs = layers.Dense(1, name='output')(x)\n",
    "    \n",
    "    # Create Model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='ThreeLayerDNN_Functional')\n",
    "    return model\n",
    "\n",
    "model = build_functional_model()\n",
    "model.summary()\n",
    "\n",
    "# Visualize model architecture\n",
    "try:\n",
    "    tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True,\n",
    "                              to_file='functional_model.png')\n",
    "    from IPython.display import Image\n",
    "    display(Image('functional_model.png'))\n",
    "except Exception as e:\n",
    "    print(f\"(Model plot visualization skipped: {e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5574af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 5: Compile and Train Model\n",
    "# ============================================================\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=50, verbose=1, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "print(\"Training with model.fit() (Functional API)...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 6: Results Visualization\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss curves from history\n",
    "axes[0].plot(history.history['loss'], label='Train', alpha=0.8)\n",
    "axes[0].plot(history.history['val_loss'], label='Val', alpha=0.8)\n",
    "axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('MSE')\n",
    "axes[0].set_title('Loss Curves'); axes[0].legend()\n",
    "axes[0].set_yscale('log'); axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Predictions\n",
    "y_final = model.predict(X_test, verbose=0)\n",
    "\n",
    "axes[1].scatter(y_test, y_final, alpha=0.5, s=10)\n",
    "mn, mx = min(y_test.min(), y_final.min()), max(y_test.max(), y_final.max())\n",
    "axes[1].plot([mn, mx], [mn, mx], 'r--', lw=2, label='Perfect')\n",
    "axes[1].set_xlabel('Actual'); axes[1].set_ylabel('Predicted')\n",
    "axes[1].set_title('Pred vs Actual'); axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "res = (y_test - y_final).flatten()\n",
    "axes[2].hist(res, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[2].axvline(0, color='r', linestyle='--')\n",
    "axes[2].set_xlabel('Residual'); axes[2].set_ylabel('Count')\n",
    "axes[2].set_title(f'Residuals (std={res.std():.4f})')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "r2 = 1 - np.sum(res**2) / np.sum((y_test.flatten() - y_test.mean())**2)\n",
    "print(f\"R²: {r2:.6f}\")\n",
    "print(f\"MAE: {np.mean(np.abs(res)):.6f}\")\n",
    "print(f\"Final train loss: {history.history['loss'][-1]:.6f}\")\n",
    "print(f\"Final val loss: {history.history['val_loss'][-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 7: Sample Predictions & MAE curve\n",
    "# ============================================================\n",
    "\n",
    "# MAE curve\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['mae'], label='Train MAE', alpha=0.8)\n",
    "plt.plot(history.history['val_mae'], label='Val MAE', alpha=0.8)\n",
    "plt.xlabel('Epoch'); plt.ylabel('MAE')\n",
    "plt.title('MAE over Epochs'); plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Denormalize\n",
    "y_to = y_test * y_std + y_mean\n",
    "y_po = y_final * y_std + y_mean\n",
    "X_to = X_test * X_std + X_mean\n",
    "\n",
    "print(\"\\nSample Predictions (Original Scale):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Idx':>5} | {'x1':>7} | {'x2':>7} | {'x3':>7} | {'Actual':>9} | {'Pred':>9} | {'Err':>7}\")\n",
    "print(\"-\" * 70)\n",
    "for i in range(15):\n",
    "    a, p = y_to[i,0], y_po[i,0]\n",
    "    print(f\"{i:5d} | {X_to[i,0]:7.3f} | {X_to[i,1]:7.3f} | {X_to[i,2]:7.3f} | {a:9.4f} | {p:9.4f} | {abs(a-p):7.4f}\")\n",
    "\n",
    "print(f\"\\nRMSE: {np.sqrt(np.mean((y_to-y_po)**2)):.4f}, R²: {r2:.6f}\")\n",
    "\n",
    "print(\"\\n=== Colab E-iii Complete ===\")\n",
    "print(\"Key: TensorFlow Functional API\")\n",
    "print(\"- Input() + Dense() layer calls create a DAG\")\n",
    "print(\"- Model(inputs, outputs) wraps the graph\")\n",
    "print(\"- model.compile() + model.fit() for training\")\n",
    "print(\"- EarlyStopping + ReduceLROnPlateau callbacks\")\n",
    "print(\"- Supports complex topologies unlike Sequential\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
