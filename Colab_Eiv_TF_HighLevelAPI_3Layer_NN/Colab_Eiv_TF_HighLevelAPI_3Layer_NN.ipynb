{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea34adc3",
   "metadata": {},
   "source": [
    "# Colab E-iv: TensorFlow High-Level API (Sequential) - 3-Layer Deep Neural Network\n",
    "\n",
    "## Overview\n",
    "- **TensorFlow/Keras `Sequential` API** - highest level of abstraction\n",
    "- Uses `model.compile()`, `model.fit()`, `model.evaluate()`, `model.predict()`\n",
    "- Built-in callbacks, metrics, and TensorBoard logging\n",
    "- Same 3-variable non-linear regression problem\n",
    "\n",
    "### Target Non-Linear Equation\n",
    "$$y = \\sin(x_1) \\cdot x_2^2 + \\cos(x_3) \\cdot x_1 + x_2 \\cdot x_3^2$$\n",
    "\n",
    "### Network Architecture\n",
    "```\n",
    "Sequential([\n",
    "    Dense(64, 'relu'),\n",
    "    Dense(32, 'relu'),\n",
    "    Dense(16, 'relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 1: Imports\n",
    "# ============================================================\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 2: Generate & Prepare Data\n",
    "# ============================================================\n",
    "N_SAMPLES = 1000\n",
    "\n",
    "x1 = np.random.uniform(-2, 2, (N_SAMPLES, 1)).astype(np.float32)\n",
    "x2 = np.random.uniform(-2, 2, (N_SAMPLES, 1)).astype(np.float32)\n",
    "x3 = np.random.uniform(-2, 2, (N_SAMPLES, 1)).astype(np.float32)\n",
    "\n",
    "y = (np.sin(x1) * x2**2 + np.cos(x3) * x1 + x2 * x3**2).astype(np.float32)\n",
    "X = np.hstack([x1, x2, x3])\n",
    "\n",
    "# Normalize\n",
    "X_mean, X_std = X.mean(axis=0), X.std(axis=0)\n",
    "y_mean, y_std = y.mean(), y.std()\n",
    "X_norm = ((X - X_mean) / X_std).astype(np.float32)\n",
    "y_norm = ((y - y_mean) / y_std).astype(np.float32)\n",
    "\n",
    "# Use sklearn train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_norm, y_norm, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Equation: y = sin(x1)*x2² + cos(x3)*x1 + x2*x3²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 3: 4D Data Visualization\n",
    "# ============================================================\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 4D: 3 spatial + color\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "sc1 = ax1.scatter(X[:, 0], X[:, 1], X[:, 2], c=y.flatten(), cmap='viridis', s=5, alpha=0.6)\n",
    "ax1.set_xlabel('x1'); ax1.set_ylabel('x2'); ax1.set_zlabel('x3')\n",
    "ax1.set_title('4D: x1,x2,x3 (color=y)')\n",
    "plt.colorbar(sc1, ax=ax1, shrink=0.5)\n",
    "\n",
    "# PCA 2D\n",
    "pca2 = PCA(n_components=2); Xp2 = pca2.fit_transform(X)\n",
    "ax2 = fig.add_subplot(132)\n",
    "sc2 = ax2.scatter(Xp2[:, 0], Xp2[:, 1], c=y.flatten(), cmap='viridis', s=5, alpha=0.6)\n",
    "ax2.set_xlabel('PC1'); ax2.set_ylabel('PC2'); ax2.set_title('PCA 2D')\n",
    "plt.colorbar(sc2, ax=ax2, shrink=0.5)\n",
    "\n",
    "# PCA 3D\n",
    "pca3 = PCA(n_components=3); Xp3 = pca3.fit_transform(X)\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "sc3 = ax3.scatter(Xp3[:, 0], Xp3[:, 1], Xp3[:, 2], c=y.flatten(), cmap='viridis', s=5, alpha=0.6)\n",
    "ax3.set_xlabel('PC1'); ax3.set_ylabel('PC2'); ax3.set_zlabel('PC3')\n",
    "ax3.set_title('PCA 3D (4D)')\n",
    "plt.colorbar(sc3, ax=ax3, shrink=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 4: Build Sequential Model (High-Level API)\n",
    "# ============================================================\n",
    "# This is the simplest, highest-level way to build a model in Keras\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Input(shape=(3,), name='input'),\n",
    "    \n",
    "    # Hidden Layer 1: 64 neurons, ReLU, He initialization\n",
    "    layers.Dense(64, activation='relu', kernel_initializer='he_normal',\n",
    "                 name='hidden_1'),\n",
    "    layers.BatchNormalization(name='bn_1'),\n",
    "    \n",
    "    # Hidden Layer 2: 32 neurons, ReLU\n",
    "    layers.Dense(32, activation='relu', kernel_initializer='he_normal',\n",
    "                 name='hidden_2'),\n",
    "    layers.BatchNormalization(name='bn_2'),\n",
    "    \n",
    "    # Hidden Layer 3: 16 neurons, ReLU\n",
    "    layers.Dense(16, activation='relu', kernel_initializer='he_normal',\n",
    "                 name='hidden_3'),\n",
    "    layers.BatchNormalization(name='bn_3'),\n",
    "    \n",
    "    # Output Layer: 1 neuron, Linear\n",
    "    layers.Dense(1, name='output')\n",
    "], name='ThreeLayerDNN_Sequential')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c917a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 5: Compile Model\n",
    "# ============================================================\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "print(\"Model compiled with:\")\n",
    "print(\"  Optimizer: Adam (lr=0.001)\")\n",
    "print(\"  Loss: MSE\")\n",
    "print(\"  Metrics: MAE, MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067a8d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 6: Define Callbacks\n",
    "# ============================================================\n",
    "\n",
    "callbacks = [\n",
    "    # Stop early if validation loss doesn't improve\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=100,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate when loss plateaus\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=30,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Save best model\n",
    "    ModelCheckpoint(\n",
    "        'best_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=0\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured:\")\n",
    "print(\"  - EarlyStopping (patience=100)\")\n",
    "print(\"  - ReduceLROnPlateau (factor=0.5, patience=30)\")\n",
    "print(\"  - ModelCheckpoint (save best)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 7: Train Model with model.fit()\n",
    "# ============================================================\n",
    "\n",
    "print(\"Training with model.fit() - highest level API...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Epochs trained: {len(history.history['loss'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46047a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 8: Evaluate Model\n",
    "# ============================================================\n",
    "\n",
    "# Built-in evaluation\n",
    "print(\"Model Evaluation (Test Set):\")\n",
    "results = model.evaluate(X_test, y_test, verbose=0)\n",
    "metric_names = model.metrics_names\n",
    "for name, val in zip(metric_names, results):\n",
    "    print(f\"  {name}: {val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 9: Results Visualization\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(history.history['loss'], label='Train', alpha=0.8)\n",
    "axes[0, 0].plot(history.history['val_loss'], label='Val', alpha=0.8)\n",
    "axes[0, 0].set_xlabel('Epoch'); axes[0, 0].set_ylabel('MSE')\n",
    "axes[0, 0].set_title('Loss Curves'); axes[0, 0].legend()\n",
    "axes[0, 0].set_yscale('log'); axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE curves\n",
    "axes[0, 1].plot(history.history['mae'], label='Train MAE', alpha=0.8)\n",
    "axes[0, 1].plot(history.history['val_mae'], label='Val MAE', alpha=0.8)\n",
    "axes[0, 1].set_xlabel('Epoch'); axes[0, 1].set_ylabel('MAE')\n",
    "axes[0, 1].set_title('MAE Curves'); axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Predictions vs Actual\n",
    "y_final = model.predict(X_test, verbose=0)\n",
    "\n",
    "axes[1, 0].scatter(y_test, y_final, alpha=0.5, s=10)\n",
    "mn, mx = min(y_test.min(), y_final.min()), max(y_test.max(), y_final.max())\n",
    "axes[1, 0].plot([mn, mx], [mn, mx], 'r--', lw=2, label='Perfect')\n",
    "axes[1, 0].set_xlabel('Actual'); axes[1, 0].set_ylabel('Predicted')\n",
    "axes[1, 0].set_title('Pred vs Actual'); axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "res = (y_test - y_final).flatten()\n",
    "axes[1, 1].hist(res, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].axvline(0, color='r', linestyle='--')\n",
    "axes[1, 1].set_xlabel('Residual'); axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].set_title(f'Residuals (std={res.std():.4f})')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "r2 = 1 - np.sum(res**2) / np.sum((y_test.flatten() - y_test.mean())**2)\n",
    "print(f\"R²: {r2:.6f}\")\n",
    "print(f\"MAE: {np.mean(np.abs(res)):.6f}\")\n",
    "print(f\"RMSE: {np.sqrt(np.mean(res**2)):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 10: 4D Prediction Visualization\n",
    "# ============================================================\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "X_test_orig = X_test * X_std + X_mean\n",
    "y_test_orig = y_test * y_std + y_mean\n",
    "y_pred_orig = y_final * y_std + y_mean\n",
    "\n",
    "# Actual\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "sc1 = ax1.scatter(X_test_orig[:, 0], X_test_orig[:, 1], X_test_orig[:, 2],\n",
    "                   c=y_test_orig.flatten(), cmap='viridis', s=15, alpha=0.7)\n",
    "ax1.set_xlabel('x1'); ax1.set_ylabel('x2'); ax1.set_zlabel('x3')\n",
    "ax1.set_title('Actual y (color)')\n",
    "plt.colorbar(sc1, ax=ax1, shrink=0.5)\n",
    "\n",
    "# Predicted\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "sc2 = ax2.scatter(X_test_orig[:, 0], X_test_orig[:, 1], X_test_orig[:, 2],\n",
    "                   c=y_pred_orig.flatten(), cmap='viridis', s=15, alpha=0.7)\n",
    "ax2.set_xlabel('x1'); ax2.set_ylabel('x2'); ax2.set_zlabel('x3')\n",
    "ax2.set_title('Predicted y (color)')\n",
    "plt.colorbar(sc2, ax=ax2, shrink=0.5)\n",
    "\n",
    "# Error\n",
    "errors = np.abs(y_test_orig - y_pred_orig).flatten()\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "sc3 = ax3.scatter(X_test_orig[:, 0], X_test_orig[:, 1], X_test_orig[:, 2],\n",
    "                   c=errors, cmap='hot', s=15, alpha=0.7)\n",
    "ax3.set_xlabel('x1'); ax3.set_ylabel('x2'); ax3.set_zlabel('x3')\n",
    "ax3.set_title('|Error| (color)')\n",
    "plt.colorbar(sc3, ax=ax3, shrink=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ef032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 11: Sample Predictions & Summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"Sample Predictions (Original Scale):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Idx':>5} | {'x1':>7} | {'x2':>7} | {'x3':>7} | {'Actual':>9} | {'Pred':>9} | {'Err':>7}\")\n",
    "print(\"-\" * 70)\n",
    "for i in range(15):\n",
    "    a, p = y_test_orig[i, 0], y_pred_orig[i, 0]\n",
    "    print(f\"{i:5d} | {X_test_orig[i,0]:7.3f} | {X_test_orig[i,1]:7.3f} | {X_test_orig[i,2]:7.3f} | {a:9.4f} | {p:9.4f} | {abs(a-p):7.4f}\")\n",
    "\n",
    "print(f\"\\nRMSE: {np.sqrt(np.mean((y_test_orig - y_pred_orig)**2)):.4f}\")\n",
    "print(f\"R²: {r2:.6f}\")\n",
    "\n",
    "print(\"\\n=== Colab E-iv Complete ===\")\n",
    "print(\"Key: TensorFlow High-Level Sequential API\")\n",
    "print(\"- keras.Sequential for model construction\")\n",
    "print(\"- model.compile() / model.fit() / model.evaluate() / model.predict()\")\n",
    "print(\"- BatchNormalization for training stability\")\n",
    "print(\"- Multiple callbacks: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\")\n",
    "print(\"- Built-in history tracking and metric logging\")\n",
    "print(\"- Simplest and most concise API\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
